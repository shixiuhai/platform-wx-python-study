import json
import os
import time
import pickle
from multiprocessing import Pool, cpu_count
from mpmath import mp, mpf, sqrt

# === é…ç½®å‚æ•° ===
SAVE_INTERVAL_SECONDS = 300           # ä¿å­˜å‘¨æœŸï¼ˆç§’ï¼‰
PRECISION = 5_000_000                 # Ï€ å°æ•°ç²¾åº¦ï¼ˆä½æ•°ï¼‰
PROGRESS_FILE = "progress.json"       # å½“å‰é¡¹æ•°æ–‡ä»¶
SUM_FILE = "pi_sum.pkl"               # å½“å‰æ€»å’Œæ–‡ä»¶ï¼ˆpickleï¼‰
PI_VALUE_FILE = "pi_value.txt"        # å½“å‰ Ï€ å€¼æ–‡ä»¶
CORES = max(cpu_count() - 1, 1)       # è‡ªåŠ¨è·å–CPUæ ¸å¿ƒæ•°ï¼Œè‡³å°‘1æ ¸
TERMS_PER_BATCH = 900                 # æ¯è½®è®¡ç®—æ€»é¡¹æ•°ï¼ˆå¿…é¡»èƒ½è¢«CORESæ•´é™¤ï¼‰

# æ ¡éªŒ batch æ˜¯å¦åˆé€‚
if TERMS_PER_BATCH % CORES != 0:
    raise ValueError("TERMS_PER_BATCH å¿…é¡»èƒ½è¢« CORES æ•´é™¤ï¼")

# è®¾ç½®é«˜ç²¾åº¦
mp.dps = PRECISION + 100

# å¸¸é‡
L = 13591409
X = 640320
X3 = X ** 3
C = 426880 * sqrt(mpf(10005))  # Chudnovsky å¸¸é‡

# === ä½¿ç”¨é€’æ¨è®¡ç®— Chudnovsky å•é¡¹å’ŒåŒºé—´å’Œ ===
def chudnovsky_term_recursive(start_k, end_k):
    total = mpf(0)
    a = mpf(1)

    # é¢„çƒ­åˆ° start_k é¡¹
    for i in range(start_k):
        numerator = -(6*i + 1)*(2*i + 1)*(6*i + 5)
        denominator = ((i + 1)**3) * X3
        a *= mpf(numerator) / mpf(denominator)

    # æ­£å¼å¼€å§‹ç´¯åŠ 
    for i in range(start_k, end_k):
        term = a * (L + 545140134 * i)
        total += term
        numerator = -(6*i + 1)*(2*i + 1)*(6*i + 5)
        denominator = ((i + 1)**3) * X3
        a *= mpf(numerator) / mpf(denominator)

    return total

# === è¯»å–ä¿å­˜è¿›åº¦ ===
def get_saved_progress():
    k = 0
    total = mpf(0)
    if os.path.exists(PROGRESS_FILE):
        with open(PROGRESS_FILE, "r") as f:
            k = json.load(f).get("k", 0)
    if os.path.exists(SUM_FILE):
        with open(SUM_FILE, "rb") as f:
            total = pickle.load(f)
    return k, total

# === è®¡ç®—å•ä¸ªæ‰¹æ¬¡ ===
def compute_batch(start_k, batch_size):
    return chudnovsky_term_recursive(start_k, start_k + batch_size)

# === ä¸»è®¡ç®—å‡½æ•° ===
def compute_pi():
    k, total = get_saved_progress()
    print(f"â–¶ ä»ç¬¬ {k} é¡¹å¼€å§‹ï¼Œç›®æ ‡ç²¾åº¦ {PRECISION} ä½ï¼Œä½¿ç”¨ {CORES} æ ¸å¿ƒ")
    print(f"ğŸ”„ å·²æ¢å¤è¿›åº¦ï¼šk = {k}ï¼Œå½“å‰æ€»å’Œä¼°å€¼ç•¥å¤§äº Ï€ â‰ˆ {str(C / total)[:14] if k else 'æœªçŸ¥'}")

    last_save = time.time()
    batch_size = TERMS_PER_BATCH // CORES

    try:
        with Pool(CORES) as pool:
            while True:
                batches = [(k + i * batch_size, batch_size) for i in range(CORES)]
                results = pool.starmap(compute_batch, batches)
                batch_sum = sum(results)
                total += batch_sum
                k += TERMS_PER_BATCH

                if time.time() - last_save >= SAVE_INTERVAL_SECONDS:
                    pi_val = C / total
                    pi_preview = str(pi_val)[:14]

                    print(f"[{time.strftime('%H:%M:%S')}] å·²è®¡ç®— {k} é¡¹ï¼ŒÏ€ â‰ˆ {pi_preview}")

                    # ä¿å­˜ Ï€ å€¼ï¼ˆæ–‡æœ¬ï¼‰
                    with open(PI_VALUE_FILE, "w") as f:
                        f.write(mp.nstr(pi_val, PRECISION))

                    # ä¿å­˜è¿›åº¦
                    with open(PROGRESS_FILE, "w") as f:
                        json.dump({"k": k}, f)

                    # ä¿å­˜æ€»å’Œ
                    with open(SUM_FILE, "wb") as f:
                        pickle.dump(total, f)

                    last_save = time.time()

    except KeyboardInterrupt:
        print("\nğŸ›‘ ç”¨æˆ·ä¸­æ–­ï¼Œæ­£åœ¨ä¿å­˜æœ€åè¿›åº¦...")
        with open(PROGRESS_FILE, "w") as f:
            json.dump({"k": k}, f)
        with open(SUM_FILE, "wb") as f:
            pickle.dump(total, f)
        print("âœ… å·²ä¿å­˜é€€å‡ºï¼Œå»ºè®®ç¨åç»§ç»­è®¡ç®—ã€‚")

if __name__ == "__main__":
    compute_pi()
